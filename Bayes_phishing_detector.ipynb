{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "import re \n",
    "\n",
    "df=pd.read_csv('phishing_site_urls.csv')\n",
    "df=shuffle(df, random_state=200)\n",
    "\n",
    "train=df.sample(frac=0.8, random_state=200) #random state is a seed value\n",
    "test=df.drop(train.index)\n",
    "n_data=train.shape[0]\n",
    "\n",
    "tokens=set()\n",
    "for i in range(len(train)):\n",
    "    tokens.update(set(re.split(r'\\.|/|\\?|=',train['URL'].iloc[i].lower())))\n",
    "    \n",
    "vectorizer = CountVectorizer(vocabulary=tokens,min_df=1./n_data,max_df=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos el vectorizador con una porcion de los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(min_df=2.2754319338668463e-06,\n",
       "                vocabulary={'', '\\x02$zn¿\\x88', '\\x05\\t¯7\\x8alø',\n",
       "                            '\\x08\\x9d)&¡\\x1fe¸\\x8b\\x1c'\n",
       "                            '¢\\x14à6r\\x18d\\xadnvy¨\\x8bð«ñ3â¸%qñ+û\\x93\\x10è\\x85'\n",
       "                            '¸\\x03\\x12$¶gz{þ',\n",
       "                            '\\nø\\x88\\n\\x85áö\\x1d¯º\\x9brê7¶\\x15§',\n",
       "                            '\\x0e\\x82âói<ý\\x0b\\x01ú1\\x19ìþqdå¯5\\x89ípç06',\n",
       "                            '\\x10\\x0e0,°n\\x10\\x0e1,q!¹(7\\x1c'\n",
       "                            '66²²$¦\\x9c¸2\\x91\\x01t¬!y((\\x93\\x8d\\x87¦ùµ\\x8...\n",
       "                            '\\x1c'\n",
       "                            '\\x88\\x97\\x89ôñ¿\\x8cj²ã\\x87crè\\x147½\\x0eýg\\t'\n",
       "                            '>¸4p!ÿ\\x8fz\\x95ôh°ú<af+¹×\\x86\\x04j÷|×¹æ\\x87ô¾£\\x95r\\x85'\n",
       "                            '\\x0b'\n",
       "                            '\\x8f',\n",
       "                            '\\x1dü\\x8dçàì\\x81ëuvmq<º',\n",
       "                            '\\x1f\\x9eók¦¾þ\\x13)j&´^áyêïfg>|½}¸!\\x11\\x85'\n",
       "                            '\\x1e'\n",
       "                            'î©q\\x87¶ú5y½êtj\\x90à&ëû\\x1b\\x1e'\n",
       "                            \"n'\\x1fo;âþ!³\\x08ñ®\\x8d\\x9af·næn\\x05\\x1c\"\n",
       "                            'î\\x93k',\n",
       "                            '\\x1få6åô', ' ', \"    url:'\", ' 1yzphtum', ' a',\n",
       "                            ' at', ' babicz123', ' biz', ' ch', ...})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(train[:50000]['URL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ajustamos el modelo mediante aprendizaje incremental, lo cual nos permite escalar el cómputo cuando no es posible almacenar los datos de entrenamiento en memoria. \n",
    "\n",
    "https://scikit-learn.org/stable/computing/scaling_strategies.html?highlight=out+core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pruebas con Bernoulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB(alpha=0)\n",
    "\n",
    "batch_size=500\n",
    "n_batches=train.shape[0]//batch_size\n",
    "for i in range(n_batches + 1):\n",
    "    mini_batch = train[i*batch_size:(i+1)*batch_size]\n",
    "    X_train = vectorizer.transform(mini_batch['URL'])\n",
    "    y_train = (mini_batch['Label']=='bad').astype('int')\n",
    "    if X_train.shape[0]>0:\n",
    "        clf.partial_fit(X_train, y_train,classes=[0,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que entrenamos el modelo, podemos evaluar en datos de test y comparar con la etiqueta verdadera.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=500\n",
    "n_batches=test.shape[0]//batch_size\n",
    "y_hat=list()\n",
    "y_true=list()\n",
    "for i in range(n_batches + 1):\n",
    "    mini_batch = test[i*batch_size:(i+1)*batch_size]\n",
    "    X_test=vectorizer.transform(mini_batch['URL'])\n",
    "    y_test=(mini_batch['Label']=='bad').astype('int')\n",
    "    if X_test.shape[0]>0:\n",
    "        y_pred=clf.predict(X_test)\n",
    "        y_true.extend(y_test)\n",
    "        y_hat.extend(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names=train['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        good       0.98      0.99      0.98     78462\n",
      "         bad       0.97      0.95      0.96     31407\n",
      "\n",
      "    accuracy                           0.98    109869\n",
      "   macro avg       0.97      0.97      0.97    109869\n",
      "weighted avg       0.98      0.98      0.98    109869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(classification_report(y_true, y_hat, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dacd0b08e66b73fb0f1ba7f8ac3fa423d6ca3523ed74657c16e7fe650626d020"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
